{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88051c3d-4a44-4ec6-8adb-c1d38653e94d",
    "_uuid": "71fff663eb9075c63db6ddd0904379ffbcdcad20"
   },
   "source": [
    "# Machine Learning Challenge\n",
    "\n",
    "## Overview\n",
    "\n",
    "The focus of this exercise is on a field within machine learning called [Natural Language Processing](https://en.wikipedia.org/wiki/Natural-language_processing). We can think of this field as the intersection between language, and machine learning. Tasks in this field include automatic translation (Google translate), intelligent personal assistants (Siri), information extraction, and speech recognition for example.\n",
    "\n",
    "NLP uses many of the same techniques as traditional data science, but also features a number of specialised skills and approaches. There is no expectation that you have any experience with NLP, however, to complete the challenge it will be useful to have the following skills:\n",
    "\n",
    "- understanding of the python programming language\n",
    "- understanding of basic machine learning concepts, i.e. supervised learning\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Download this notebook!\n",
    "2. Answer each of the provided questions, including your source code as cells in this notebook.\n",
    "3. Share the results with us, e.g. a Github repo.\n",
    "\n",
    "### Task description\n",
    "\n",
    "You will be performing a task known as [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis). Here, the goal is to predict sentiment -- the emotional intent behind a statement -- from text. For example, the sentence: \"*This movie was terrible!\"* has a negative sentiment, whereas \"*loved this cinematic masterpiece*\" has a positive sentiment.\n",
    "\n",
    "To simplify the task, we consider sentiment binary: labels of `1` indicate a sentence has a positive sentiment, and labels of `0` indicate that the sentence has a negative sentiment.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset is split across three files, representing three different sources -- Amazon, Yelp and IMDB. Your task is to build a sentiment analysis model using both the Yelp and IMDB data as your training-set, and test the performance of your model on the Amazon data.\n",
    "\n",
    "Each file can be found in the `input` directory, and contains 1000 rows of data. Each row contains a sentence, a `tab` character and then a label -- `0` or `1`. \n",
    "\n",
    "**Notes**\n",
    "- Feel free to use existing machine learning libraries as components in you solution!\n",
    "- Suggested libraries: `sklearn` (for machine learning), `pandas` (for loading/processing data), `spacy` (for text processing).\n",
    "- As mentioned, you are not expected to have previous experience with this exact task. You are free to refer to external tutorials/resources to assist you. However, you will be asked to justfify the choices you have made -- so make you understand the approach you have taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head \"./input/imdb_labelled.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "387106cd-e89a-462f-b204-a91a73d12137",
    "_uuid": "cbd1a4b1d16ce7db6def7b3b393b48618d7e4777"
   },
   "source": [
    "# Tasks\n",
    "### 1. Read and concatenate data into test and train sets.\n",
    "### 2. Prepare the data for input into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head \"./input/yelp_labelled.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np \n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "def clean_text(sentence):\n",
    "\n",
    "    processed_feature = re.sub(r'\\W', ' ', sentence)\n",
    "\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "    return processed_feature.lower().strip()\n",
    "\n",
    "\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    tokens = nlp(sentence)   \n",
    "    tokens = [ token for token in tokens if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "    tokens = [ token.lemma_.lower().strip() if token.lemma_ != \"-PRON-\" else token.lower_ for token in tokens ]\n",
    "    return tokens\n",
    "\n",
    "    \n",
    "def spacy_tokenizer_v2(sentence):\n",
    "\n",
    "    tokens = nlp(sentence)\n",
    "    \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [{\"LOWER\": \"is\"},  {\"OP\": \"*\"},{\"LOWER\": \"not\"}]\n",
    "    matcher.add(\"is_not\", [pattern])\n",
    "    \n",
    "    matches = matcher(tokens)\n",
    "    match_pos = []\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  \n",
    "        match_pos.append(start)\n",
    "        match_pos.append(end-1)\n",
    "        \n",
    "\n",
    "    tokens = [ token for token in tokens if token.i not in match_pos ]\n",
    "\n",
    "    tokens = [ token for token in tokens if not token.is_stop and not token.is_punct and not token.is_space ]\n",
    "    \n",
    "    tokens = [ token.lemma_.lower().strip() if token.lemma_ != \"-PRON-\" else token.lower_ for token in tokens ]\n",
    "    if match_pos:\n",
    "        tokens.append(\"is not\")\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(\"./input/yelp_labelled.txt\", sep='\\t', header=None)\n",
    "\n",
    "train_data = train_data.append(pd.read_csv(\"./input/imdb_labelled.txt\", sep='\\t', header=None))\n",
    "features = train_data.iloc[:, 0].values\n",
    "labels = train_data.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8240a39-7002-435b-ba45-ac859d209f7f",
    "_uuid": "69c6d7ea240a191abfaaf00574f09521944387d7"
   },
   "source": [
    "#### 2a: Find the ten most frequent words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('movie', 179), ('film', 163), ('good', 146), ('0', 138), ('1', 124), ('food', 114), ('place', 109), ('like', 94), ('great', 88), ('time', 84)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "complete_doc = nlp(' '.join(features))\n",
    "\n",
    "words = [token.text for token in complete_doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f4cc399e-66c4-4bf7-a8e1-03711372c7b4",
    "_uuid": "eb8b033dc4a841702ae52d4ec71e7718b3257dda"
   },
   "source": [
    "### 3. Train your model and justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n",
    "test_data = pd.read_csv(\"./input/amazon_cells_labelled.txt\", sep='\\t', header=None)\n",
    "test_feature = train_data.iloc[:, 0].values\n",
    "test_labels = train_data.iloc[:, 1].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a5840b2-c84c-42f6-9fc9-4fed64e48298",
    "_uuid": "f4eeecd64b54cc05098affe6cca4c40204af8ecf"
   },
   "source": [
    "### 4. Evaluate your model using metric(s) you see fit and justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9456521739130435\n",
      "Logistic Regression Precision: 0.9458850056369785\n",
      "Logistic Regression Recall: 0.9469525959367946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', TfidfVectorizer(tokenizer = spacy_tokenizer)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(features,labels)\n",
    "\n",
    "predicted = pipe.predict(test_feature)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, prediction, label in zip(test_feature, predicted, test_labels):\n",
    "  if prediction != label:\n",
    "    print(input, 'has been classified as ', prediction, 'and should be ', label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. just try to improve the model a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9462242562929062\n",
      "Logistic Regression Precision: 0.9479638009049773\n",
      "Logistic Regression Recall: 0.945823927765237\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', TfidfVectorizer(tokenizer = spacy_tokenizer_v2)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "\n",
    "pipe.fit(features,labels)\n",
    "\n",
    "predicted = pipe.predict(test_feature)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, prediction, label in zip(test_feature, predicted, test_labels):\n",
    "  if prediction != label:\n",
    "    print(input, 'has been classified as ', prediction, 'and should be ', label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.950228832951945\n",
      "Logistic Regression Precision: 0.9414364640883978\n",
      "Logistic Regression Recall: 0.9616252821670429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', TfidfVectorizer(tokenizer = spacy_tokenizer)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "pipe.fit(features,labels)\n",
    "predicted = pipe.predict(test_feature)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(test_labels, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9954233409610984\n",
      "Logistic Regression Precision: 0.996606334841629\n",
      "Logistic Regression Recall: 0.9943566591422122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', TfidfVectorizer(tokenizer = spacy_tokenizer)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "pipe.fit(features,labels)\n",
    "predicted = pipe.predict(test_feature)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(test_labels, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9954233409610984\n",
      "Logistic Regression Precision: 0.9954853273137697\n",
      "Logistic Regression Recall: 0.9954853273137697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', TfidfVectorizer(tokenizer = spacy_tokenizer_v2)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "pipe.fit(features,labels)\n",
    "predicted = pipe.predict(test_feature)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(test_labels, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(test_labels, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
